
二维静态图像序列（SSFP, steady state free precession）的左心和四腔心分割是进行其他各种分析之前重要的一步．
考虑到对比度、外观、方向、病人心脏位置、临床切面、扫描仪以及协议的不同，心脏的全自动语义分割是一个非常难以解决的问题．
本文中，我们提出一个新的卷积神经网络（CNN），它可以同时完成定位，变换到典型方向，以及语义分割．
首先，对输入图像进行一个\hl{初始}分割；然后在初始分割过程中学习到特征会用来预测将图像变换到一个典型方向所需的参数；最后，对变换后的图像进行细分割．
在这个工作中，我们训练了不同深度的 \omeganet 来检测五个类别（短轴切面，SA；四腔心切面，4C；两腔心切面，2C），而不给出任何的先验知识．
这个工作比之前的工作更加有挑战性．
网络训练使用的数据来自肥厚型心肌病受试者（HCM, $N = \NumPtO{}$）和健康受试者（$N = \NumPtC{}$）．
网络的性能比起没有定位和方向信息的 \UNet{} 比起来好很多，IoU 为 $0.858$ vs $0.834$．
此外，为了与其他工作进行对比，我们从头开始，在 2017 MICCAI 自动心脏诊断竞赛（ACDC）公开数据集上进行训练．
\omeganet{} 在左室和右室血池表现优异，而在右室心肌的分割结果稍差．
我们可以得出结论，这个网络结构对比以往其他方法有更多的有点，对于生物医学分割任务来说也更加通用．
